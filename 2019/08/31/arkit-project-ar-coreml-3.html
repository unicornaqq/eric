<p>今天我们来研究下另外一个项目的代码： Gesture-Recognition-101-CoreML-ARKit。</p>

<p>这个项目的主要功能：捕捉手势，在屏幕的中央来显示对应的动画手势。</p>

<h3 id="viewcontroller">ViewController</h3>

<p>我们还是从类ViewController的实现开始讲起。</p>

<p>在这个类中，我们需要如下的几个要素：</p>
<ul>
  <li>ARSCNView</li>
  <li>dispatchqueue</li>
  <li>request</li>
  <li><strong>viewDidload</strong></li>
  <li><strong>viewWillAppear</strong></li>
  <li><strong>viewWillDisappear</strong></li>
  <li>renderer</li>
  <li>loopCoreMLUpdate</li>
  <li>updateCoreML</li>
  <li>classificationCompleteHandler</li>
</ul>

<p>以上函数中，加粗的是重新实现了父类的方法，实现定制化。其他的函数都是该类内部函数，供其自己使用。</p>

<h3 id="arscnview">ARSCNView</h3>
<p>这个是arkit项目的必备品。
结合我们之前看过的几个项目，我们可以大概总结一下对这个对象进行的操作。</p>

<ul>
  <li>指定delegate，将其关联到ViewController</li>
  <li>关联指定的场景，在ARkit中，我们使用的几乎都是SCNScene。</li>
  <li>启动/终止session。</li>
</ul>

<h4 id="scnscene">SCNScene</h4>
<p>这是一个3d场景，3d场景中的物体对象是以node的形式组织起来的。</p>

<h3 id="dispatchqueue">dispatchqueue</h3>
<p>本章，我们将详细讨论下dispatchqueue，因为它在arkit+coreml的项目中很重要。</p>

<p>在apple的开发网站上，dispatchqueue的定义是这样子的。</p>
<blockquote>
  <p>An object that manages the execution of tasks serially or concurrently on your app’s main thread or on a background thread.
一个对象，它可以管理任务的执行，可以是顺序执行，也可以是并发执行，任务是在app的主线程或者后台线程上执行的。</p>
</blockquote>

<h4 id="该队列的几个特性">该队列的几个特性</h4>
<ul>
  <li>像所有的队列一样，它是先进先出的。</li>
  <li>提交给该队列的任务是由系统提供的一个线程池来执行
    <ul>
      <li>除了代表你的app的主线程的那个dispatchqueue之外，系统不能保证你提交的任务是给哪个线程去执行的</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>需要注意的是：不要在主线程上顺序的执行一个任务，否则会造成死锁。</p>
</blockquote>

<p>既然是线程池，那么就会面临线程池中的线程资源被用光的问题，那么如何才能避免呢？</p>

<ul>
  <li>如果你的任务想并发执行，那么尽量确保你的任务不要block其所在的线程
    <ul>
      <li>因为线程一旦被堵住，系统就会使用线程池中的其他线程来执行queue中的其他任务。</li>
    </ul>
  </li>
  <li>尽量不要给每个类创建过多的私有并发dispatchqueue，如果可能的话，尽量将任务提交给全局并发dispatchqueue。
    <ul>
      <li>那样既可以保证队列的顺序化行为，同时又不至于引发线程资源紧张的问题。</li>
    </ul>
  </li>
</ul>

<p>所以在我们这个项目中，创建了一个私有的queue。</p>

<h3 id="request">request</h3>
<p>这是一个request的数组，里边放的呢是VNRequest，VNRequest是个基类，是不能被实例化的。但是它的各种子类是可以被实例化的，在本项目中用到的VNCoreMLRequest就是其中的一种，它是VNImageBasedRequest的子类。所以这几个类之间的关系是。</p>

<pre><code class="language-mermaid">graph TD
A[VNCoreMLRequest] --&gt; |继承| B(VNImageBasedRequest)
B --&gt; |继承| C[VNRequest]

</code></pre>
<p><em>VNCoreMLRequest的主要功能就是使用模型进行预测，并将结果返回。</em></p>

<h3 id="viewdidload">viewDidLoad</h3>
<p>视角/视图加载完成之后会调用这个函数，那么在这个函数中会做什么事情呢？</p>
<ul>
  <li>调用父类的同名函数</li>
  <li>将视图的delegate设置为当前的viewController</li>
  <li>为视图创建场景</li>
  <li>选择模型</li>
  <li>创建VNCoreMLRequest
    <ul>
      <li>指定模型</li>
      <li>指定结果处理函数</li>
    </ul>
  </li>
  <li>开始模型处理的循环</li>
</ul>

<h3 id="函数loopcoremlupdate">函数loopCoreMLUpdate</h3>
<p>这个函数做的事情从代码表面来看很简单，它给dispatchqueue提交了一个任务。任务是以代码块的形式提交的。在该代码块中，</p>
<ul>
  <li>触发request来使用模型处理数据
    <ul>
      <li>在本项目中，就是相机截取到的image</li>
    </ul>
  </li>
  <li>递归的调用自己，使得循环继续。</li>
</ul>

<p>正如前面提到的，在本函数中，使用的async的方式向dispatchQueue提交任务，之所以如此，是因为在使用模型来处理相机截取的image是需要花时间的，同步执行的话势必会将线程堵死，此时的表现就是视角中的图片死掉了。</p>

<p>既然是异步处理，那自然需要提供在模型处理完数据之后的处理函数。该处理函数在定义创建request的时候就已经指定好了。</p>

<h3 id="结果处理函数">结果处理函数</h3>
<ul>
  <li>读取在request的结果中保存着的模型处理的结果
    <ul>
      <li>根据模型的不同，返回的内容也会不同，这个是由模型决定的</li>
      <li>在本项目中，模型是用来进行分类的，所有处理的结果当然就是模型从当前的图像中识别出来的物体。</li>
    </ul>
  </li>
  <li>将模型处理结果按照你自己想要的方式进行拼接，处理。</li>
  <li>渲染你的结果</li>
</ul>

<h3 id="结果的最终渲染">结果的最终渲染</h3>
<p>结果的渲染是提交给全局的main dispatchQueue进行处理的，而且是以异步的方式（这主要是为了防止死锁）。注意，此处提交的也是一个序列化的代码块。</p>

<p>所以这里有两个queue，一个queue是私有queue，专门用来处理request。一个是全局的主queue，这个queue专门用来在拿到了处理结果之后，进行结果的渲染。</p>

<p>在拿到了处理结果之后，将额外处理完的文字图像赋值给了两个特殊的对象，debugTextView和textOverlay。</p>

<p>开始的时候，不是很理解，问题在于，我这里只是做了赋值，那什么时候显示到屏幕上了，是不是需要另外去渲染。后来发现，其实并不需要，特殊之处就在于debugTextView和textOverlay就像dock一样，它是一直在屏幕上的。我们在后期给他们赋值会直接显示在dock中，不需要另外的渲染。</p>

<p>至此，项目研究完毕。</p>

<h3 id="后续">后续</h3>
<p>在后续的章节会再分析一两个项目，弄清楚要实现一个AR+CoreML要实现哪些功能/函数。
另外，研究一下不同的模型对应的接口，看看他们之间的异同之处，为后续将自己训练的模型融入到app中捉准备。</p>

